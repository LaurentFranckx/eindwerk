Next Word Prediction 
========================================================

<style type="text/css">
.small-code pre code {
font-size: 1.3em;
}
</style>


Central objectives and constraints:


- Generate "next" word prediction for English sentence with 3 datasets: Twitter, news articles and blogs
- Underlying prediction algorithm should be precise 
- Keep data size for app within Shiny limits
- Quick response to user input: prediction within 1 sec
- Compensate for user spelling mistakes with approximate matching 
- Default:  single word prediction but user can ask  3-word prediction


Data: sources and approach 
========================================================

<small>

- Stopwords are integral part of content: keep them 
- No stemming: users want complete word, not its stem
- Eliminate words and n-grams with low count (less than 4 occurrences):   
  - improves speed and reduces memory use  
  - eliminates  'noise' and does not affect overall precision 
- Algorithm optimized for 4-grams, but also uses prediction based on 3, 2- and 1-grams: back-off  with 'discounting' (see next slide)
- Differences between 3 datasets requires separate analysis - merging "blogs" and "news" leads to marginal improvements in precision but is slower 
- Link to app and user guidance:

https://lfranckx.shinyapps.io/Cap4/



</small>



Description of algorithm
========================================================

![alt text](algor_flow.PNG)





Average precision in validation sets
========================================================

```{r, echo=FALSE, fig.width=7.5,fig.height=3.5,dpi=300,out.width="1920px",height="1080px"}
library(ggplot2)
library(plyr)
library(reshape)
#load("D:/coursera/dsc_capstone/mean_accuracy.RData")
#name_accumat <- "accuracy_test"
name_accumat <- "accuracy_test_new"
load(file = paste(name_accumat, "RData", sep="."))

accu_mat_twitter <- accu_mat[accu_mat$TrainCorpus== "twitter"&  accu_mat$i ==5, ]
accu_mat_news <- accu_mat[accu_mat$TrainCorpus== "news"&  accu_mat$i ==5, ]
accu_mat_blogs <- accu_mat[accu_mat$TrainCorpus== "blogs"&  accu_mat$i ==5, ]

library(ggplot2)

plot_train_test <- function(train_df, test){
  id_vars <- c("k","TestCorpus")
  meas_vars <- c("accu1","accu2","accu3")
  accu_mat <- train_df[train_df$TestCorpus == test,  ]
  accu_mat_twitter_plot <- accu_mat[ , c(id_vars,"accu1")]
  accu_mat_twitter_plot$words <- c(1)
  names(accu_mat_twitter_plot) <- gsub("accu1","precision",names(accu_mat_twitter_plot))
  accu_mat_twitter_plot2 <- accu_mat[ , c(id_vars, "accu2")]
  accu_mat_twitter_plot2$words <- c(2)
  names(accu_mat_twitter_plot2) <- gsub("accu2","precision",names(accu_mat_twitter_plot2))
  accu_mat_twitter_plot3 <- accu_mat[ , c(id_vars,"accu3")]
  accu_mat_twitter_plot3$words <- c(3)
  names(accu_mat_twitter_plot3) <- gsub("accu3","precision",names(accu_mat_twitter_plot3))
  
  accu_mat_twitter_plot_new <- rbind(accu_mat_twitter_plot, accu_mat_twitter_plot2)
  accu_mat_twitter_plot_new <- rbind(accu_mat_twitter_plot_new, accu_mat_twitter_plot3)
  names(accu_mat_twitter_plot_new) <- gsub("k","Discount_factor",names(accu_mat_twitter_plot_new))
  
  accu_mat_twitter_plot_new$words <- as.factor(accu_mat_twitter_plot_new$words)
  names(accu_mat_twitter_plot_new) <- gsub("words","suggested_words",names(accu_mat_twitter_plot_new))
  return(accu_mat_twitter_plot_new)
  #ggplot(accu_mat_twitter_plot_new, aes(Discount_factor, precision, colour = suggested_words)) + geom_point() + facet_grid(.  ~ TestCorpus)
  #ggplot(accu_mat_twitter_plot_new, aes(Discount_factor, precision, colour = suggested_words)) + geom_point() 
  
}

twitplot <- plot_train_test(accu_mat_twitter, "blogs")
twitplot$TrainCorpus <- "twitter"
newsplot <- plot_train_test(accu_mat_news, "blogs")
newsplot$TrainCorpus <- "news"
blogplot <- plot_train_test(accu_mat_blogs, "news")
blogplot$TrainCorpus <- "blogs"

toplot <- rbind(twitplot,blogplot)
toplot <- rbind(toplot,newsplot)

fmt <- function(){
    function(x) format(x,nsmall = 2,scientific = FALSE)
}

ggplot(toplot, aes(Discount_factor, precision, colour = suggested_words)) + geom_point() + facet_grid(.  ~ TrainCorpus) +  scale_x_continuous(breaks = seq(0,1,by =0.2))
 #   scale_x_continuous(labels = fmt())



```

<small>

Interpretation: see next slide

</small>

Determinants of  precision
========================================================

<small>
- Validation sets: for each dataset, random sample of 500 n grams from other dataset ("blogs" for "news" and "twitter", "news" for "blogs")
- Role of discount factor (*k*)
 - except for "blogs", *k* does not matter for 1-word precision 
 - impact of *k* on 2- or 3-word precision ambiguous and small 
 - for "blogs": trade-off between 1- and 3- word precision
 - overall, set *k* = 0: give same weight to likelihoods based on lower n-grams as for those based in higher n-grams
- moving from 1 to 3 word suggestion has much larger impact on overall predictive value than varying *k*
- With external test set (https://github.com/jan-san/dsci-benchmark): top-1 precision around 12 %, top-3 precision: 16 %



</small>
